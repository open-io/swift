[DEFAULT]
bind_ip = 127.0.0.1
bind_port = 5000
workers = 1
#use_realpath_on_usr1 = false
max_clients = 8192
backlog = 16384
user = %USER%
log_facility = LOG_LOCAL0
log_level = DEBUG
log_name = oioswift
#log_custom_handlers = swift_logger_ltsv.ltsvlogger.config
#log_format_ltsv = X-OVH-TOKEN:XXXX	log_type:log	pid:{pid}	log_level:{level}	request_id:{txn_id}	exc_text:{exc_text}	exc_filename:{exc_filename}exc_lineno:{exc_lineno}	message:{message}

cors_allow_origin = https://www.ovh.com,https://ovh.com,http://localhost:9000,https://*.dtci.ovhcloud.dev,https://*.dtci.ovhcloud.tools
cors_expose_headers = X-Storage-Policy,X-Container-Read

eventlet_debug = true
sds_namespace = OPENIO
sds_proxy_url = http://127.0.0.1:6000
sds_default_account = AUTH_demo
sds_connection_timeout = 3.0
sds_read_timeout = 35.0
sds_write_timeout = 35.0
# Number of connection pools (one pool per endpoint)
sds_pool_connections = 50
# Number of open TCP connections per connection pool.
# Keep this param low unless there are many coroutines per process.
sds_pool_maxsize = 50
sds_max_retries = 0
sds_tls = False

# The default storage policy is the same as for oio-sds.
# To change it, change the default oio-sds storage policy.
oio_storage_policies = EC21,THREECOPIES,TWOCOPIES,SINGLE
auto_storage_policies = EC21,THREECOPIES:0,EC21:100000

[pipeline:main]
pipeline = catch_errors gatekeeper healthcheck s3-logging cache listing_formats bulk iam replication_ratelimit bucket_ratelimit replication s3api tempauth proxy-logging copy slo dlo versioned_writes symlink keymaster encryption proxy-logging proxy-server

[filter:catch_errors]
use = egg:swift#catch_errors

[filter:gatekeeper]
use = egg:swift#gatekeeper

[filter:healthcheck]
use = egg:swift#healthcheck

[filter:proxy-logging]
use = egg:swift#proxy_logging
#log_msg_template = TO_BE_DELETED

[filter:s3-logging]
use = egg:swift#s3_logging
log_msg_template = X-OVH-TOKEN:XXXX	log_type:access	client_ip:{client_ip}	remote_addr:{remote_addr}	remote_port:{remote_port}	request_origin:{request_origin}	requester:{requester}	domain:{domain}	path:{path}	client_etag:{client_etag}	website:{website}	account:{account}	bucket:{bucket}	object:{object}	version_id_float:{version_id}	storage_class:{storage_class}	storage_class_domain:{storage_class_domain}	method:{method}	operation:{operation}	status_int:{status_int}	error_code:{error_code}	error_detail:{error_detail}	backend_error:{backend_error}	backend_service_id:{backend_service_id}	bytes_recvd_int:{bytes_recvd}	bytes_sent_int:{bytes_sent}	request_id:{transaction_id}	request_time_float:{request_time}	start_time_float:{start_time}	ttfb_float:{ttfb}	user_agent:{user_agent:.256}	signature_version:{signature_version}	authentication_type:{authentication_type}	aws_chunked:{aws_chunked}	ratelimit:{ratelimit}	perfdata:{perfdata}	pid:{pid}
access_log_headers = False
access_log_headers_only = 
perfdata = False
perfdata_user_agent_0 = .
access_log_statsd_host = 127.0.0.1
access_log_statsd_port = 8125
access_log_statsd_default_sample_rate = 1.0
access_log_statsd_sample_rate_factor = 1.0
customer_access_logging = true
pre_log = false

[filter:replication_ratelimit]
use = egg:swift#replicator_ratelimit
log_only_on_global_ratelimiting = false
ratelimit = -1
group.COPY = REST.COPY.OBJECT,REST.COPY.PART
ratelimit.COPY = -1
group.READ = REST.COPY.OBJECT_GET,REST.GET.ACL,REST.GET.BUCKET,REST.GET.BUCKETVERSIONS,REST.GET.CORS,REST.GET.INTELLIGENT_TIERING,REST.GET.LIFECYCLE,REST.GET.LOCATION,REST.GET.LOGGING_STATUS,REST.GET.OBJECT,REST.GET.OBJECT_ACL,REST.GET.OBJECT_LOCK_CONFIGURATION,REST.GET.OBJECT_LOCK_LEGALHOLD,REST.GET.OBJECT_LOCK_RETENTION,REST.GET.OBJECT_TAGGING,REST.GET.PART,REST.GET.REPLICATION,REST.GET.TAGGING,REST.GET.UPLOAD,REST.GET.UPLOADS,REST.GET.VERSIONING,REST.GET.WEBSITE,REST.HEAD.BUCKET,REST.HEAD.OBJECT,REST.HEAD.PART,REST.OPTIONS.PREFLIGHT,SEPARATOR.READ_BUCKET_METADATA,SOAP.ListAllMyBuckets,WEBSITE.GET.OBJECT,WEBSITE.HEAD.OBJECT
ratelimit.READ = 900
group.WRITE = BATCH.DELETE.OBJECT,REST.DELETE.BUCKET,REST.DELETE.CORS,REST.DELETE.INTELLIGENT_TIERING,REST.DELETE.LIFECYCLE,REST.DELETE.OBJECT,REST.DELETE.OBJECT_TAGGING,REST.DELETE.REPLICATION,REST.DELETE.TAGGING,REST.DELETE.UPLOAD,REST.DELETE.WEBSITE,REST.POST.UPLOAD,REST.POST.UPLOADS,REST.PUT.ACL,REST.PUT.BUCKET,REST.PUT.CORS,REST.PUT.INTELLIGENT_TIERING,REST.PUT.LIFECYCLE,REST.PUT.LOGGING_STATUS,REST.PUT.OBJECT,REST.PUT.OBJECT_ACL,REST.PUT.OBJECT_LOCK_CONFIGURATION,REST.PUT.OBJECT_LOCK_LEGALHOLD,REST.PUT.OBJECT_LOCK_RETENTION,REST.PUT.OBJECT_TAGGING,REST.PUT.PART,REST.PUT.REPLICATION,REST.PUT.TAGGING,REST.PUT.VERSIONING,REST.PUT.WEBSITE,SEPARATOR.WRITE_BUCKET_METADATA
ratelimit.WRITE = 300
sampling_period = 1
bucket_ratelimit_ttl = 60
asychronous_increment = true
memcache_servers = 127.0.0.1:11211
max_connections = 10
tries = 1
connect_timeout = 0.95
io_timeout = 0.1
pool_timeout = 0.1
error_suppression_interval = 30
error_suppression_limit = 10

[filter:bucket_ratelimit]
use = egg:swift#bucket_ratelimit
log_only_on_global_ratelimiting = true
ratelimit = -1
group.COPY = REST.COPY.OBJECT,REST.COPY.PART
ratelimit.COPY = 50
group.READ = REST.COPY.OBJECT_GET,REST.GET.ACL,REST.GET.BUCKET,REST.GET.BUCKETVERSIONS,REST.GET.CORS,REST.GET.INTELLIGENT_TIERING,REST.GET.LIFECYCLE,REST.GET.LOCATION,REST.GET.LOGGING_STATUS,REST.GET.OBJECT,REST.GET.OBJECT_ACL,REST.GET.OBJECT_LOCK_CONFIGURATION,REST.GET.OBJECT_LOCK_LEGALHOLD,REST.GET.OBJECT_LOCK_RETENTION,REST.GET.OBJECT_TAGGING,REST.GET.PART,REST.GET.REPLICATION,REST.GET.TAGGING,REST.GET.UPLOAD,REST.GET.UPLOADS,REST.GET.VERSIONING,REST.GET.WEBSITE,REST.HEAD.BUCKET,REST.HEAD.OBJECT,REST.HEAD.PART,REST.OPTIONS.PREFLIGHT,SEPARATOR.READ_BUCKET_METADATA,SOAP.ListAllMyBuckets,WEBSITE.GET.OBJECT,WEBSITE.HEAD.OBJECT
ratelimit.READ = 4000
group.WRITE = BATCH.DELETE.OBJECT,REST.DELETE.BUCKET,REST.DELETE.CORS,REST.DELETE.INTELLIGENT_TIERING,REST.DELETE.LIFECYCLE,REST.DELETE.OBJECT,REST.DELETE.OBJECT_TAGGING,REST.DELETE.REPLICATION,REST.DELETE.TAGGING,REST.DELETE.UPLOAD,REST.DELETE.WEBSITE,REST.POST.UPLOAD,REST.POST.UPLOADS,REST.PUT.ACL,REST.PUT.BUCKET,REST.PUT.CORS,REST.PUT.INTELLIGENT_TIERING,REST.PUT.LIFECYCLE,REST.PUT.LOGGING_STATUS,REST.PUT.OBJECT,REST.PUT.OBJECT_ACL,REST.PUT.OBJECT_LOCK_CONFIGURATION,REST.PUT.OBJECT_LOCK_LEGALHOLD,REST.PUT.OBJECT_LOCK_RETENTION,REST.PUT.OBJECT_TAGGING,REST.PUT.PART,REST.PUT.REPLICATION,REST.PUT.TAGGING,REST.PUT.VERSIONING,REST.PUT.WEBSITE,SEPARATOR.WRITE_BUCKET_METADATA
ratelimit.WRITE = 300
sampling_period = 1
bucket_ratelimit_ttl = 60
asychronous_increment = true
memcache_servers = 127.0.0.1:11211
max_connections = 10
tries = 1
connect_timeout = 0.95
io_timeout = 0.1
pool_timeout = 0.1
error_suppression_interval = 30
error_suppression_limit = 10

[filter:cache]
use = egg:swift#oiomemcache
memcache_servers = 127.0.0.1:11211
max_connections = 10
tries = 1
connect_timeout = 0.95
io_timeout = 0.1
pool_timeout = 0.1
error_suppression_interval = 30
error_suppression_limit = 10
oio_cache = True
oio_cache_ttl = 3600

[filter:listing_formats]
use = egg:swift#listing_formats

[filter:bulk]
use = egg:swift#bulk

[filter:iam]
use = egg:swift#oioiam
# log_level = DEBUG
# Only the scheme part(oio://) of url is used, the address and port are bogus
connection = %IAM_RULES_CONN%
connection_timeout = 0.5
read_timeout = 5.0

[filter:s3api]
use = egg:swift#s3api
max_upload_part_num = 10000
log_s3api_command = True
max_bucket_listing = 1000
s3_acl = True
bucket_db_prefix = s3bucket:
check_bucket_owner = True
bucket_db_enabled = True
# Only the scheme part(oio://) of url is used, the address and port are bogus
bucket_db_connection = oio://
force_swift_request_proxy_log = True
location = RegionOne
storage_classes = STANDARD,EXPRESS_ONEZONE,STANDARD_IA
auto_storage_policies_STANDARD = EC21,TWOCOPIES:0,EC21:102400
auto_storage_policies_EXPRESS_ONEZONE = EC:-2,SINGLE
auto_storage_policies_STANDARD_IA = THREECOPIES
storage_domain = s3.regionone.perf.lo.team-swift.ovh:EXPRESS_ONEZONE,s3.regionone.io.lo.team-swift.ovh,s3.regionone.ia.lo.team-swift.ovh:STANDARD_IA,s3.sbg.perf.cloud.ovh.net
force_storage_domain_storage_class = false
standardize_default_storage_class = true
check_bucket_storage_domain = false
check_ip_whitelist = true
max_multi_delete_objects = 1000
allow_anonymous_path_requests = false
# Max server-side copy size should be lower or equal to max_file_size
max_server_side_copy_size = 104857600
max_server_side_copy_throughput = 1048576
s3_only = true
landing_page = https://www.ovhcloud.com/en/public-cloud/object-storage/
enable_bucket_replication = true
replicator_ids = s3-replication
enable_lifecycle = true
enable_object_lock = true
enable_website = true
enable_access_logging = true
retry_after = 1
#enable_beta_features = true
enable_encryption = true

[filter:tempauth]
use = egg:swift#tempauth
# Main user of the account AUTH_demo
user_demo_demo = DEMO_PASS .admin .reseller_admin
# Unpriviledged users of the account AUTH_demo
user_demo_user1 = USER_PASS
user_demo_user2 = USER_PASS

# Main user of the account AUTH_account2
user_account2_admin = ADMIN_PASS .admin
# Unpriviledged user of the account AUTH_account2
user_account2_user1 = USER_PASS

# Log delivery user
user64_bG9nZ2Vy_LmxvZ19kZWxpdmVyeQ = LOG_DELIVERY  # logger:.log_delivery

[filter:copy]
object_post_as_copy = False
use = egg:swift#copy
# In order to keep a connection active during a potentially long PUT request,
# clients may request that Swift send whitespace ahead of the final response
# body. This whitespace will be yielded at most every yield_frequency seconds.
# yield_frequency = 10

[filter:slo]
use = egg:swift#slo
max_manifest_segments = 10000
concurrency = 10
# True enable the async deletion of parts.
# Response is made to the customer once the manifest is deleted, therefore,
# the object will not be accessible very fast (in comparison of the sync mode
# where parts are deleted during the request).
allow_async_delete = True

[filter:dlo]
use = egg:swift#dlo

[filter:versioned_writes]
use = egg:swift#versioned_writes
allow_versioned_writes = True
allow_object_versioning = True
allow_oio_versioning = True

[filter:symlink]
use = egg:swift#symlink

[filter:keymaster]
use = egg:swift#ssec_keymaster
# Fall back on the standard keymaster if the user does not provide a key
fallback_on_keymaster = false
# When a new bucket is created, create an associated key in the KMS.
# When this is disabled, buckets with keys will continue using them,
# but new buckets won't get a key.
# Both use_oio_kms and enable_encryption must be set to True to enable SSE-S3.
use_oio_kms = true
# Activate encryption for these accounts. Empty whitelist will be ignored.
account_whitelist = 
# How long (seconds) to keep in cache the bucket secret
secret_cache_time = 1
# How long (seconds) to keep in cache the fact that there is no bucket secret
no_secret_cache_time = 300

meta_version_to_write = 3
encryption_root_secret_0 = TmV4dC1HZW4gT2JqZWN0IFN0b3JhZ2UgJiBTZXJ2ZXJsZXNzIENvbXB1dGluZwo=

active_root_secret_id = 0

# Encryption of inbound object data may be disabled by setting 'disable_encryption' to True.
# However, all encryption middleware should remain in the pipeline in order for existing encrypted data to be read.
[filter:encryption]
use = egg:swift#encryption
disable_encryption = False
# Use a different checksum algorithm for the cyphered object data. We need to
# keep computing the plaintext's md5 to comply with the protocol, but the
# ciphertext's checksum can be anything else supported by the backend.
ciphertext_hash_algo = blake3
# Enable SSE-C encryption mode: objects are cyphered only when the requester
# provides an encryption key.
ssec_mode = True

[app:proxy-server]
object_post_as_copy = False
use = egg:swift#oio_proxy
allow_account_management = True
sds_chunk_checksum_algo = blake3
account_autocreate = True
#require_proxy_protocol = True

[filter:replication]
use = egg:swift#replication
